---
# title: "{ingemat}§2e|0l|2e|2m|2e|1n|0[-]t|1o|3[++]s|2  d|2s|2{202201}[26°c[10°c]"
title: "Elementos DS"
pagetitle: "06-Introducción-al-modelamiento"
subtitle: "06 Introducción al modelamiento <code><small>ranger partykit yardstick</small></code>"
author: "<br>Joshua Kunst<br>@jbkunst"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    self_contained: no
    css: ["css/xaringan-themer.css", "css/styles.css"]
    lib_dir: libs    
    nature:
      titleSlideClass: ["left", "middle"]
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
source(here::here("R/00-xaringan-knitr-setup.R"))

library(klassets)
library(tidyverse)
library(equatiomatic)
library(patchwork)

set.seed(123)

df <- klassets::sim_xy(
  n = 250,
  beta0 = 3,
  beta1 = 0.5,
  x_dist = purrr::partial(runif, min = 0, max = 100),
  error_dist = purrr::partial(rnorm, sd = 5)
) |> 
  mutate(
    y = y +
      (4 * sin(x /  5)) * ifelse(x > 50, 0, 1) +
      (4 * sin(x / 20)) * ifelse(x > 75, 0, 1),
    y = y - min(y) + 1,
    y = y**(1/3)
    )

plot(df)
```

## Modelamiento

En un principio pensaremos como el modelamiento a la _simplificación_ de un fenómeno.

Supongamos un fenómeno/evento observable y registramos dos medidas $(x, y)$, y supongamos además
que observamos esto $n$ veces teniendo dicha cantidad de pares $(x_i, y_i)$.

La idea es representar dicho fenómeno, o relación entre las variables $x$ e $y$ a través de
una función o regla más sencilla.

Esta representación no servirá para:

- **Entender** como se relacionan estas variables, es decir, como varia una variable
a medida que la otra cambia.

- Realizar **predicciones** en caso que el costo de observar un $y_j$ dado un $x_j$ sea alto,
o demore cierto tiempo en observar. Ejemplo seria que             

---

## Fenómeno

```{r, echo = FALSE}
knitr::opts_chunk$set(
  fig.height = 3,
  fig.width  = 9,
  # out.width = "80%",
  # fig.align = " center",
  echo = FALSE
)
```


```{r}
plot(df)
```

Supongamos este fenómeno, en donde $x$ puede ser _cantidad de cafeína ingerida_ e $y$
_tiempo en horas de aceleramiento cardiaco_ en ciertos pacientes/ratones.

---

## Primer modelo

```{r}
fit_lm <- fit_linear_model(df)

lm_mod <- attr(fit_lm, "model")

mod_eq      <- equatiomatic::extract_eq(lm_mod)
mod_eq_coef <- equatiomatic::extract_eq(lm_mod, use_coefs = TRUE)

mod_eq      <- str_c("$", str_remove_all(mod_eq, "$$|\\(|\\)"), "$")
mod_eq_coef <- str_c("$", str_remove_all(mod_eq_coef, "$$|\\(|\\)"), "$")

plot(fit_lm, alpha = 1)
```

En este caso particular, una idea primera interpretación sería postular que `r mod_eq`.


---

## Primer modelo: uso I

```{r}
plot(fit_lm, alpha = 1)
```

Una posible _modelo_ es `r mod_eq_coef`. De esta forma, a través de _esta_ representacón podemos mencionar que por cada $1$ unidad de $x$, la de $y$ aumenta en $`r as.vector(round(coef(lm_mod)[2], 2))`$. 

---

## Primer modelo: uso II

```{r}
dnew <- tibble(x = 75)
dnew <- mutate(dnew, y = predict(lm_mod, newdata = dnew))

plot(fit_lm, alpha = 1) +
  geom_point(aes(x, y), data = dnew, size = 8, color = "darkred") +
  geom_point(aes(x, y), data = dnew, size = 5, color = "white") 
```

De la misma forma podemos predecir que un paciente al cual se le da $`r dnew$x`$ unidades, sufrirá
$`r round(dnew$y, 2)`$ horas de _aceleramiento cardiaco_.


---

## ¿Cuál/Qué es el mejor modelo?

```{r}
n_models <- 20

models   <- tibble(
  alpha = rnorm(n = n_models, mean = coef(lm_mod)[1], sd = 0.1),
  beta  = rnorm(n = n_models, mean = coef(lm_mod)[2], sd = 0.01)
)

plot(df) +
  geom_abline(
    aes(slope = beta, intercept = alpha), data = models,
    color = scales::muted("blue"), 
    alpha = 0.2,
    size = 0.8
    )
```

Hay `r n_models` modelos en el gráfico (algunos malos!!). Necesitamos encontrar el mejor modelo especificando nuestra intuición que un buen modelo está _cerca de los datos_. Necesitamos una manera de **cuantificar** la distancia entre los datos y un modelo.

---

## Métrica de un modelo

```{r}
plot(fit_lm, alpha = 1) +
  geom_linerange(
    data = fit_lm,
    aes(x = x, ymin = y, ymax = prediction),
    color = scales::muted("blue"), 
    alpha = 0.2,
    size = 0.8
  )
```

Podemos definir un buen modelo cuando las distancias $\hat{e}_i$ (lineas azules) en promedio son
pequeñas. El modelo mostrado es el "mejor" modelo en términos de minimizar $\sum \hat{e}^2_i/n$ y dentro 
de la _familia de modelos_ `r mod_eq`.


---

## Falencias de un _modelo_


```{r}
dproblemas_1 <- fit_lm |> 
  arrange(x) |> 
  mutate(id = row_number()) |> 
  filter(between(x, 25, 50), y > prediction) |> 
  mutate(lbl = "Subestimaciones")

dproblemas_2 <-  fit_lm |> 
  arrange(x) |> 
  mutate(id = row_number()) |> 
  filter(between(id, 0, 10), y < prediction) |> 
  mutate(lbl = "Problemas de ajuste")

dproblemas <- bind_rows(dproblemas_1, dproblemas_2)

plot(fit_lm, alpha = 1) +
  geom_linerange(
    data = fit_lm,
    aes(x = x, ymin = y, ymax = prediction),
    color = scales::muted("blue"), 
    alpha = 0.1,
    size = 0.5
  ) +
  ggforce::geom_mark_ellipse(
    data = dproblemas,
    aes(x = x, y = y, label = lbl, group = lbl),
    alpha = 0.1, fill = "gray80",
    label.fontface = c("plain"),
    color = scales::muted("red"), 
    size = 1.5,
    label.fill = "transparent",
    label.fontsize = 10,
  )
```

Si bien el modelo presentado simple, fácil de explicar y entender, esta _familia de modelos_ 
no es suficientemente flexible para _pasar cerca_ de todos los puntos.


---

## Modelo con mayor <small><small>sobre</small></small>ajuste

```{r}
fit_overfit <- fit_loess(df, span = 0.01)
# fit_overfit <- fit_regression_random_forest(df, ntree = 10000)
# fit_overfit <- fit_linear_model_tree(df, maxdepth = Inf, alpha = 1)

plot(fit_overfit, alpha = 1)
```

Eventualmente se puede tener un modelo que pase por todos los puntos, sin embargo
estos modelos _sobre ajustan_, en lugar de aprender las tendencias implicitas, memorizan
el ruido y no pueden generalizar datos más allá de los de entrenamiento.


---

## Otras familias de modelos


```{r, fig.height = 4.5, fig.width  = 9}
p1 <- plot(fit_regression_tree(df)) + labs(subtitle = "Árbol de regresión")
p2 <- plot(fit_linear_model_tree(df)) + labs(subtitle = "Árboles lineales")
p3 <- plot(fit_loess(df), span = 0.01) + labs(subtitle = "Regresion polinomial local")
p4 <- plot(fit_mars(df)) + labs(subtitle = "Multivariate Adaptive Regression Splines")
p5 <- plot(fit_linear_model(df, order = 10, stepwise = TRUE), alpha = 1) + labs(subtitle = "Regresion lineal polinomial")
p6 <- plot(fit_regression_random_forest(df, ntree = 50, maxdepth = 3), alpha = 1) + labs(subtitle = "Random Forest")

p1 + p2 + p3 + p4 + p5 + p6 + plot_layout(nrow = 2) & labs(x = NULL, y = NULL) 
```

---

## Ajustar (FIT) Modelos


Para ajustar un modelo se debe tener claro:

- La familia de modelos a ajustar: Regresion lineal, Random Forest, Arbol de Regresión, etc.
- La variable respuesta, la que se quiere modelar o predecir.
- Los datos a los cuales se le aplica el algoritmo o modelo.
- Parámetros adicionales del modelo.

<br/>

Veremos algunos ejemplos utilizando los siguientes datos

```{r}
dplyr::glimpse(df)
```


---

## Ajustar (FIT) Modelos en R


```{r, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

De forma general la sintaxis es como sigue:

`funcion_ajuste(formula, datos, parámetros)`

Por ejemplo:

```{r, eval=FALSE}
lm(y ~ x, data = datos)

ranger(y ~ ., data = datos, num.trees = 500, max.depth = 10)

ctree(y ~ ., data = datos, control = ctree_control(maxdepth = 3))
```

De forma general la formula `y ~ .` significa, modelar $y$ en función
de todas las columnas en `data`.


---

`r flipbookr::chunk_reveal("fit_lm", title = "## Ajustar Modelo lineal", widths = c(1, 1))`

```{r fit_lm, include = FALSE}


mod_lm <- lm(y ~ x, data = df)

mod_lm
```


---

`r flipbookr::chunk_reveal("fit_rf", title = "## Ajustar Random Forest", widths = c(1, 1))`

```{r fit_rf, include = FALSE}
library(ranger)

mod_rf <- ranger(y ~ x,
                 data = df,
                 num.trees = 500,
                 max.depth = 10)

mod_rf
```

---

`r flipbookr::chunk_reveal("fit_ar", title = "## Ajustar Arbol de Regresión", widths = c(1, 1))`

```{r fit_ar, include = FALSE}
library(partykit)

mod_ar <- ctree(y ~ x,
                data = df, 
                control = ctree_control(maxdepth = 3))

mod_ar
```

---

## Realizar Predicciones

Para realizar predicciones se debe poseer:

- El modelo ajustado ya con datos.
- Nuevo datos con las variables utilizadas para su ajuste.
- A veces se requiere de un parámetro adicional, por ejemplo en el caso de los 
Random Forest se puede realizar la predicción utilizando solo los primeros $n$ árboles,
o a veces uno puede obtener la clase estimada en un ejercicio de clasificación o la
probabilidad de la pertenencia a una clase.

---

## Realizar Predicciones en R

De forma general es:

`predict(modelo, nuevosdatos, parámetros_adicionales)`

Por ejemplo:

```{r, eval=FALSE}
nuevos_datos <- df[c(1, 20, 30, 50), ]

mod <- lm(y ~ x, data = df)

predict(mod, nuevos_datos)
```


---

`r flipbookr::chunk_reveal("perdict_in_r", title = "## Ejemplo en R", widths = c(1, 1))`

```{r perdict_in_r, include = FALSE}
set.seed(123)

nuevos_datos <- sample_n(df, 5)

mod_lm <- lm(y ~ x, data = df)

predict(mod_lm, nuevos_datos)

# otro modelo, mismos datos
library(partykit)

mod_ar <- ctree(
  y ~ x,
  data = df, 
  control = ctree_control(maxdepth = 3)
  )

predict(mod_ar, nuevos_datos)
```

---

## Métricas de Evaluación

Las metricas de evaluación, nos ayudan a resumir que tan bien se ajusta o predice un modelo.

Consideremos los siguientes datos en una tarea de _regresión_, es decir, predecir
una variable continua $y$.

```{r, echo=FALSE}
df_metrix_example <- sample_n(fit_lm, 5)
df_metrix_example
```

El error de predicción se define como $e_i = y_i - prediction_i$ y existen diferentes
métricas para este conjunto de valores $e_i$ para resumir que tan grandes son, y poder así
comparar con otros modelos o en otros datos.

---

## Métricas de Evaluación: Regresión

En el caso de regresión, las metricas se basan en resumir (promedio, mediana, etc)
los errores de predicción $e_i$

<br/>

$$\text{Mean squared error: MSE} = {mean(e^2_i)} = {\sum{e^2_i/n}} $$

$$\text{Root mean squared error: RMSE} = \sqrt{mean(e^2_i)} = \sqrt{\sum{e^2_i/n}} $$

$$\text{Mean absolute percentage error: MAPE} = mean(|p_i|) = \sqrt{\sum{|p_i|/n}} = \sqrt{\sum{|(e_i/y_i)|/n}}$$


---

`r flipbookr::chunk_reveal("metrics_regression", title = "## Métricas de Evaluación: Regresión (en R)", widths = c(1, 1))`

```{r metrics_regression, include = FALSE}
df_metrix_example |> 
  mutate(
    error = y - prediction,
    percentage_error = error/y
    ) |> 
  summarise(
    mse = mean(error^2),
    rmse = sqrt(mse),
    mape = mean(abs(percentage_error))
  )
```


---

## Ejercicio

Considere los datos `data_xy_fit_pred.csv` en la carpeta `data\` del repositorio
del curso.

1. Conozca los datos. Grafíquelos. 
1. Separe los datos en 2 `data.frame`s, `dtrain` y `dtest` utilizando la columna
`muestra` en los datos de su agrado.
1. Con `dtrain` ajuste al menos 2 modelos.
1. En `dtrain` agregue las columnas de valores predichos asociadas a cada uno
de los modelos. Vuelva a graficar incluyendo los resultados de los modelos.
1. Obtenga el error cuadrático medio de ambos modelos en la muestra de entrenamiento. 
¿Cuál es mejor?
1. Repita los dos puntos anteriores con la muestra de desarrollo.

---

## Ejercicio <small>(cont)</small>

Modifique la columna `muestra` tal que los valores de `x` menores a 750 sean
de entrenamiento y el resto sean para validación. Repita todo ejercicio anterior 
con esta nueva marca. No olvide graficar.

```{r, echo=FALSE}
set.seed(123)

N <- 1000

dfex <- sim_xy(n = N, x_dist = runif) |> 
  dplyr::mutate(y = y + 2*sin(5 * x) + sin(10 * x)) |> 
  mutate(
    x = row_number(), 
    muestra = ifelse(runif(N) < .7, "train", "test")
    )

f <- here::here("data/data_xy_fit_pred.csv")
if(!file.exists(f)) readr::write_delim(dfex, f)

ggplot(dfex) + geom_point(aes(x, y, color = muestra)) +
  scale_color_viridis_d(begin = 0.2, end = 0.8, option = "A")
```

---

## Ejemplor RUT vs año de nacimiento

```{r, echo = FALSE}
knitr::opts_chunk$set(
  fig.height = 4.5,
  fig.width  = 9,
  # out.width = "80%",
  # fig.align = " center",
  echo = FALSE
)
```

```{r, echo = FALSE}
data(idyob10k)

plot(idyob10k) +
  labs(y = "Año de nacimiento", x = "RUT", title = "10.000 registros") +
  scale_x_continuous(labels = scales::comma)
```

---

## Ejemplo: RUT vs año de nacimiento - Modelos

```{r, echo = FALSE}
df <- idyob10k

m <- list(
  "Árbol de regresión"          = fit_regression_tree(df, maxdepth = 4),
  "Árboles lineales"            = fit_linear_model_tree(df),
  "Regresion polinomial local"  = fit_loess(df),
  "Multivariate Adaptive Regression Splines" = fit_mars(df),
  "Regresion lineal polinomial" = fit_linear_model(df, order = 5, stepwise = TRUE),
  "Random Forest"               = fit_regression_random_forest(df, ntree = 100, maxdepth = 5)
)

nms <- names(m)

plots <- map2(m, nms, function(mod, nm){
  
  plot(mod) + labs(subtitle = nm)
  
})

plots |> 
  reduce(`+`) + plot_layout(nrow = 2) & 
  labs(x = NULL, y = NULL) &
  scale_y_continuous(limits = c(1930, 2000)) &
  scale_x_continuous(labels = NULL)
```

---

## Ejemplo: RUT vs año de nacimiento - Métricas

```{r, echo = FALSE}
dfm <- bind_rows(m, .id = "modelo") |> 
  mutate(
    modelo = fct_inorder(modelo),
    error = y - prediction
    )

dfm |> 
  group_by(modelo) |> 
  summarise(
    RMSE = Metrics::rmse(y, prediction),
    MAPE = Metrics::mape(y, prediction)
  ) |> 
  arrange(RMSE)
```

---

## Ejemplo: RUT vs año de nacimiento - Residuos

```{r, echo = FALSE}
ggplot(dfm, aes(x, error)) +
  geom_point(alpha = 0.01, color = "gray60") +
  geom_smooth(color = "darkred") +
  facet_wrap(vars(modelo)) +
  scale_x_continuous(labels = scales::comma, breaks = scales::pretty_breaks(2))
```

---

## Métricas de Evaluación: Classificación



- ROC

- Accuracy

- Matriz de Confusión


---

## Ejercicio

Considere los datos `datos_creditos.csv` en la carpeta `data\` del repositorio
del curso (los de la tarea I).

1. Separe los datos en 2 `data.frame`s, `dtrain` y `dtest` utilizando los primeros
3000 registros para entrenamiento, y el resto para test.
1. Con `dtrain` ajuste un modelo de random forest para predecir el valor 
de la variable `estado` utilizando el paquete/función `randomForest`.
1. En `dtrain` agregue la columnas de valores predichos asociadas al modelo.
1. Obtenga al tasa de correcta clasificación en la muestra de entrenamiento. 
¿Cuál es mejor?
1. Repita los dos puntos anteriores con la muestra de desarrollo y compare.




